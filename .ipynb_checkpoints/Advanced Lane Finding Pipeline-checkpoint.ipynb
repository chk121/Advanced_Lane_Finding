{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\"\"\"\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProcessImage:\n",
    "\n",
    "    def perspective_transform(self, calibrated):\n",
    "        img_size = (calibrated.shape[1],  calibrated.shape[0])\n",
    "        src = np.float32([[800, 505], [1110, 680], [280, 680], [520, 505]])\n",
    "        dst = np.float32([[1110, 0], [1110, img_size[1]], [280, img_size[1]], [280, 0]])\n",
    "        # Given src and dst points, calculate the perspective transform matrix\n",
    "        M = cv2.getPerspectiveTransform(src, dst)\n",
    "        # Warp the image using OpenCV warpPerspective()\n",
    "        warped = cv2.warpPerspective(calibrated, M, img_size)\n",
    "        Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "        return warped, Minv\n",
    "    \n",
    "    def gaussian_blur(img, kernel=5):\n",
    "        # Function to smooth image\n",
    "        blur = cv2.GaussianBlur(img,(kernel,kernel),0)\n",
    "        return blur\n",
    "    \n",
    "    def abs_sobel_thresh(img, orient, sobel_kernel, thresh):\n",
    "        \n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        # Apply x or y gradient with the OpenCV Sobel() function\n",
    "        # and take the absolute value\n",
    "        if orient == 'x':\n",
    "            abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0))\n",
    "        if orient == 'y':\n",
    "            abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1))\n",
    "        # Rescale back to 8 bit integer\n",
    "        scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "        # Create a copy and apply the threshold\n",
    "        binary_output = np.zeros_like(scaled_sobel)\n",
    "        # Here I'm using inclusive (>=, <=) thresholds, but exclusive is ok too\n",
    "        binary_output[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "\n",
    "        # Return the result\n",
    "        return binary_output\n",
    "\n",
    "    def thresholded_binary(self, transformed, sx_thresh=(20, 100), s_thresh=(170, 255), b_thresh=(155, 200), l_thresh=(225, 255)):\n",
    "\n",
    "        #lab = cv2.cvtColor(transformed, cv2.COLOR_BGR2Lab)\n",
    "        b_channel = transformed[:,:,0]\n",
    "        # Convert image to HLS scheme\n",
    "        hls = cv2.cvtColor(transformed, cv2.COLOR_BGR2HLS)\n",
    "        s_channel = hls[:,:,2]\n",
    "        \"\"\"\n",
    "        luv = cv2.cvtColor(transformed, cv2.COLOR_BGR2Luv)\n",
    "        l_channel = luv[:,:,0]\n",
    "        \"\"\"\n",
    "        hsv = cv2.cvtColor(transformed, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        # Define color ranges and apply color mask\n",
    "        yellow_hsv_low  = np.array([ 0, 100, 100])\n",
    "        yellow_hsv_high = np.array([ 50, 255, 255])\n",
    "\n",
    "        white_hsv_low  = np.array([  20,   0,   180])\n",
    "        white_hsv_high = np.array([ 255,  80, 255])\n",
    "        # get yellow and white masks \n",
    "        mask_yellow = cv2.inRange(hsv,yellow_hsv_low,yellow_hsv_high)\n",
    "        mask_white = cv2.inRange(hsv,white_hsv_low,white_hsv_high)\n",
    "        \n",
    "        # Combine white and yellow masks into 1\n",
    "        mask_lane = cv2.bitwise_or(mask_yellow,mask_white)\n",
    "        \n",
    "        \"\"\"\n",
    "        img_abs_x = self.abs_sobel_thresh(l_channel,orient='x',sobel_kernel=5,thresh=(50,225))\n",
    "        img_abs_y = self.abs_sobel_thresh(l_channel,orient='y',sobel_kernel=5,thresh=(50,225))\n",
    "        wraped2 = np.copy(cv2.bitwise_or(img_abs_x,img_abs_y))\n",
    "        \n",
    "        img_abs_x = self.abs_sobel_thresh(s_channel,orient='x',sobel_kernel=5,thresh=(50,255))\n",
    "        img_abs_y = self.abs_sobel_thresh(s_channel,orient='y',sobel_kernel=5,thresh=(50,255))\n",
    "        wraped3 = np.copy(cv2.bitwise_or(img_abs_x,img_abs_y))\n",
    "        \n",
    "        # Combine sobel filter information from L and S channels.\n",
    "        ls_cmb = cv2.bitwise_or(wraped2,wraped3)\n",
    "        ls_cmb = self.gaussian_blur(ls_cmb,25)\n",
    "        \n",
    "        # Combine masks from sobel and color masks.\n",
    "        combined = np.zeros_like(ls_cmb)\n",
    "        combined[(mask_lane >= .5)|(ls_cmb >= .5)] = 1\n",
    "        \"\"\"\n",
    "        gray = cv2.cvtColor(transformed, cv2.COLOR_BGR2GRAY)\n",
    "        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "        abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "        scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "\n",
    "        # Threshold x gradient\n",
    "        sxbinary = np.zeros_like(scaled_sobel)\n",
    "        sxbinary[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 1    \n",
    "        \n",
    "        # Threshold color channel\n",
    "        \n",
    "        s_binary = np.zeros_like(s_channel)\n",
    "        s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "        \"\"\"\n",
    "        l_binary = np.zeros_like(l_channel)\n",
    "        l_binary[(l_channel >= l_thresh[0]) & (l_channel <= l_thresh[1])] = 1\n",
    "        \"\"\"\n",
    "        b_binary = np.zeros_like(b_channel)\n",
    "        b_binary[(b_channel >= b_thresh[0]) & (b_channel <= b_thresh[1])] = 1\n",
    "        \n",
    "        combined = np.zeros_like(sxbinary)\n",
    "        combined[(sxbinary == 1) | (s_binary == 1) | (b_binary == 1)] = 1\n",
    "        \n",
    "        return combined\n",
    "\n",
    "    def find_lane_pixels(self, binary_warped):\n",
    "        # Take a histogram of the bottom half of the image\n",
    "        histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "        # Find the peak of the left and right halves of the histogram\n",
    "        # These will be the starting point for the left and right lines\n",
    "        midpoint = np.int(histogram.shape[0]//2)\n",
    "        leftx_base = np.argmax(histogram[:midpoint])\n",
    "        rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "        # HYPERPARAMETERS\n",
    "        # Choose the number of sliding windows\n",
    "        nwindows = 9\n",
    "        # Set the width of the windows +/- margin\n",
    "        margin = 50\n",
    "        # Set minimum number of pixels found to recenter window\n",
    "        minpix = 50\n",
    "\n",
    "        # Set height of windows - based on nwindows above and image shape\n",
    "        window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "        # Identify the x and y positions of all nonzero pixels in the image\n",
    "        nonzero = binary_warped.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Current positions to be updated later for each window in nwindows\n",
    "        leftx_current = leftx_base\n",
    "        rightx_current = rightx_base\n",
    "\n",
    "        # Create empty lists to receive left and right lane pixel indices\n",
    "        left_lane_inds = []\n",
    "        right_lane_inds = []\n",
    "        \n",
    "        # Step through the windows one by one\n",
    "        for window in range(nwindows):\n",
    "            # Identify window boundaries in x and y (and right and left)\n",
    "            win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "            win_y_high = binary_warped.shape[0] - window*window_height\n",
    "            win_xleft_low = leftx_current - margin\n",
    "            win_xleft_high = leftx_current + margin\n",
    "            win_xright_low = rightx_current - margin\n",
    "            win_xright_high = rightx_current + margin\n",
    "\n",
    "            # Identify the nonzero pixels in x and y within the window\n",
    "            good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) &\n",
    "                             (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "            good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "                              (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "\n",
    "            # Append these indices to the lists\n",
    "            left_lane_inds.append(good_left_inds)\n",
    "            right_lane_inds.append(good_right_inds)\n",
    "\n",
    "            # If > minpix pixels, recenter next window\n",
    "            # (`right` or `leftx_current`) on their mean position\n",
    "            if len(good_left_inds) > minpix:\n",
    "                leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "            if len(good_right_inds) > minpix:        \n",
    "                rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "        # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "        try:\n",
    "            left_lane_inds = np.concatenate(left_lane_inds)\n",
    "            right_lane_inds = np.concatenate(right_lane_inds)\n",
    "        except ValueError:\n",
    "            # Avoids an error if the above is not implemented fully\n",
    "            pass\n",
    "\n",
    "        # Extract left and right line pixel positions\n",
    "        leftx = nonzerox[left_lane_inds]\n",
    "        lefty = nonzeroy[left_lane_inds] \n",
    "        rightx = nonzerox[right_lane_inds]\n",
    "        righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "        return leftx, lefty, rightx, righty\n",
    "\n",
    "    def search_around_existing_poly(self, binary_warped):\n",
    "        # Choose the width of the margin around the previous polynomial to search\n",
    "        margin = 50\n",
    "\n",
    "        # Grab activated pixels\n",
    "        nonzero = binary_warped.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "\n",
    "        # Set the area of search based on activated x-values\n",
    "        # within the +/- margin of polynomial function\n",
    "        left_lane_inds = (nonzerox > (self.left_fit[0]*(nonzeroy**2) + self.left_fit[1]*nonzeroy + self.left_fit[2] - margin)) & (nonzerox < (self.left_fit[0]*(nonzeroy**2) + self.left_fit[1]*nonzeroy + self.left_fit[2] + margin))\n",
    "        right_lane_inds = (nonzerox > (self.right_fit[0]*(nonzeroy**2) + self.right_fit[1]*nonzeroy + self.right_fit[2] - margin)) & (nonzerox < (self.right_fit[0]*(nonzeroy**2) + self.right_fit[1]*nonzeroy + self.right_fit[2] + margin))\n",
    "\n",
    "        # Again, extract left and right line pixel positions\n",
    "        leftx = nonzerox[left_lane_inds]\n",
    "        lefty = nonzeroy[left_lane_inds] \n",
    "        rightx = nonzerox[right_lane_inds]\n",
    "        righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "        return leftx, lefty, rightx, righty\n",
    "\n",
    "    def fit_polynomial(self, leftx, lefty, rightx, righty, ploty):\n",
    "        self.left_fit = np.polyfit(lefty, leftx, 2)\n",
    "        self.right_fit = np.polyfit(righty, rightx, 2)\n",
    "        \n",
    "        ## Check error between current coefficient and on from previous frame\n",
    "        if frame_num == 0:\n",
    "            self.last_known_good_left_fit = self.left_fit\n",
    "            self.last_known_good_right_fit = self.right_fit\n",
    "            frame_num = 1\n",
    "\n",
    "        err_L = np.sum((self.left_fit[0] - self.last_known_good_left_fit[0])**2)\n",
    "        err_L = np.sqrt(err_L)\n",
    "        \n",
    "        if err_L > .0005:\n",
    "            self.left_fit = self.last_known_good_left_fit\n",
    "        else:\n",
    "            self.left_fit = .05*self.left_fit + .95*self.last_known_good_left_fit\n",
    "\n",
    "        try:\n",
    "            left_fitx = self.left_fit[0]*ploty**2 + self.left_fit[1]*ploty + self.left_fit[2]\n",
    "            self.last_known_good_left_fit = self.left_fit\n",
    "        except TypeError:\n",
    "            self.left_fit = None\n",
    "            left_fitx = self.last_known_good_left_fit[0]*ploty**2 + self.last_known_good_left_fit[1]*ploty +  self.last_known_good_left_fit[2]\n",
    "            \n",
    "        ## Check error between current coefficient and on from previous frame\n",
    "        err_R = np.sum((self.right_fit[0] - self.last_known_good_left_fit[0]**2))\n",
    "        err_R = np.sqrt(err_R)\n",
    "        if err_R > .0005:\n",
    "            self.right_fit = self.last_known_good_right_fit\n",
    "        else:\n",
    "            self.right_fit = .05*self.right_fit + .95*self.last_known_good_right_fit\n",
    "        \n",
    "        try:\n",
    "            right_fitx = self.right_fit[0]*ploty**2 + self.right_fit[1]*ploty + self.right_fit[2]\n",
    "            self.last_known_good_right_fit = self.right_fit\n",
    "        except TypeError:\n",
    "            self.right_fit = None\n",
    "            self.right_fitx = self.last_known_good_right_fit[0]*ploty**2 + self.last_known_good_right_fit[1]*ploty + self.last_known_good_right_fit[2]\n",
    "\n",
    "        # offset calculation\n",
    "        y_eval = np.max(ploty)\n",
    "\n",
    "        bottom_left_x = self.left_fit[0]*y_eval**2 + self.left_fit[1]*y_eval + self.left_fit[2] if self.left_fit is not None else 0\n",
    "        bottom_right_x = self.right_fit[0]*y_eval**2 + self.right_fit[1]*y_eval + self.right_fit[2] if self.right_fit is not None else 0\n",
    "        center = (bottom_left_x + bottom_right_x) / 2\n",
    "        offset = (1280/2 - center) * (3.7/700)\n",
    "\n",
    "        return left_fitx, right_fitx, ploty, offset\n",
    "\n",
    "    def measure_curvature(self, fit_coeffs, y_eval):\n",
    "        if fit_coeffs is not None and fit_coeffs[0] != 0:\n",
    "            return ((1 + (2 * fit_coeffs[0] * y_eval + fit_coeffs[1]) ** 2) ** (3/2)) / abs(2 * fit_coeffs[0])\n",
    "        else:\n",
    "            raise Exception(\"invalid\")\n",
    "\n",
    "    def measure_curvature_real(self, leftx, lefty, rightx, righty, ploty):\n",
    "        '''\n",
    "        Calculates the curvature of polynomial functions in meters.\n",
    "        '''\n",
    "        # Define conversions in x and y from pixels space to meters\n",
    "        ym_per_pix = 30.0/720 # meters per pixel in y dimension\n",
    "        xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "        y_eval = np.max(ploty) * ym_per_pix\n",
    "        left_fit_cr = np.polyfit(lefty * ym_per_pix, leftx * xm_per_pix, 2) \n",
    "        try:\n",
    "            left_curverad = measure_curvature(left_fit_cr, y_eval)\n",
    "            self.last_known_good_left_curverad = left_curverad\n",
    "        except:\n",
    "            left_curverad = self.last_known_good_left_curverad\n",
    "\n",
    "        right_fit_cr = np.polyfit(righty * ym_per_pix, rightx * xm_per_pix, 2) \n",
    "        try:    \n",
    "            right_curverad = self.measure_curvature(right_fit_cr, y_eval)\n",
    "            self.last_known_good_right_curverad = right_curverad\n",
    "        except:\n",
    "            right_curverad = self.last_known_good_right_curverad\n",
    "\n",
    "        return (left_curverad + right_curverad) / 2\n",
    "\n",
    "    def find_lane_lines(self, binary_warped):\n",
    "        # sanity check\n",
    "        if self.left_fit is not None and self.right_fit is not None:\n",
    "            leftx, lefty, rightx, righty = self.search_around_existing_poly(binary_warped)\n",
    "        else:\n",
    "            leftx, lefty, rightx, righty = self.find_lane_pixels(binary_warped)\n",
    "\n",
    "        ploty = np.linspace(0, binary_warped.shape[0] - 1, binary_warped.shape[0])\n",
    "        left_fitx, right_fitx, ploty, offset = self.fit_polynomial(leftx, lefty, rightx, righty, ploty)\n",
    "        avg_curvature = self.measure_curvature_real(leftx, lefty, rightx, righty, ploty)\n",
    "\n",
    "        return  left_fitx, right_fitx, avg_curvature, ploty, offset\n",
    "\n",
    "    def project_lane_detection_back_to_image(self, thresholded_binary_image, left_fitx, right_fitx, ploty, Minv, calibrated):\n",
    "        shape = thresholded_binary_image.shape\n",
    "        # Create an image to draw the lines on\n",
    "        warp_zero = np.zeros_like(thresholded_binary_image).astype(np.uint8)\n",
    "        color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "        # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "        pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "        pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "        pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "        cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "        # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "        newwarp = cv2.warpPerspective(color_warp, Minv, (shape[1], shape[0])) \n",
    "        # Combine the result with the original image\n",
    "        result = cv2.addWeighted(calibrated, 1, newwarp, 0.3, 0)\n",
    "        return result\n",
    "\n",
    "    def __init__(self, cal_images):\n",
    "        # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "        objp = np.zeros((6*9,3), np.float32)\n",
    "        objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "        # Arrays to store object points and image points from all the images.\n",
    "        objpoints = [] # 3d points in real world space\n",
    "        imgpoints = [] # 2d points in image plane.\n",
    "        for fname in cal_images:\n",
    "            img = cv2.imread(fname)\n",
    "            gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "            ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "            if ret == True:\n",
    "                objpoints.append(objp)\n",
    "                imgpoints.append(corners)\n",
    "\n",
    "        img = cv2.imread(cal_images[0])\n",
    "        ret, self.mtx, self.dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img.shape[1::-1], None, None)\n",
    "        \n",
    "        # Polynomial fit values from the previous frame\n",
    "        self.left_fit = None\n",
    "        self.right_fit = None\n",
    "        self.last_known_good_left_fit = None\n",
    "        self.last_known_good_right_fit = None\n",
    "        self.last_known_good_left_curverad = 0\n",
    "        self.last_known_good_right_curverad = 0\n",
    "\n",
    "    def __call__(self, image):\n",
    "        undistorted = cv2.undistort(image, self.mtx, self.dist, None, self.mtx)\n",
    "        transformed, Minv = self.perspective_transform(undistorted)\n",
    "        thresholded_binary_image = self.thresholded_binary(transformed)\n",
    "        left_fitx, right_fitx, avg_curvature, ploty, offset = self.find_lane_lines(thresholded_binary_image)\n",
    "        result = self.project_lane_detection_back_to_image(thresholded_binary_image, left_fitx, right_fitx, ploty, Minv, undistorted)\n",
    "        cv2.putText(result, f\"radius of curvature = {avg_curvature} m\", (30, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "        cv2.putText(result, f\"offset = {offset} m\", (30, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'frame_num' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-00cffc6027a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprocess_img_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProcessImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'camera_cal/calibration*.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mwhite_clip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfl_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_img_obj\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#NOTE: this function expects color images!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'white_clip.write_videofile(output, audio=False)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36mfl_image\u001b[0;34m(self, image_func, apply_to)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mby\u001b[0m \u001b[0manother\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mimage_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \"\"\"\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mgf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;31m# --------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36mfl\u001b[0;34m(self, fun, apply_to, keep_duration)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;31m#mf = copy(self.make_frame)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mnewclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_make_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-181>\u001b[0m in \u001b[0;36mset_make_frame\u001b[0;34m(self, mf)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36moutplace\u001b[0;34m(f, clip, *a, **k)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;34m\"\"\" Applies f(clip.copy(), *a, **k) and returns clip.copy()\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mnewclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnewclip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36mset_make_frame\u001b[0;34m(self, mf)\u001b[0m\n\u001b[1;32m    692\u001b[0m         \"\"\"\n\u001b[1;32m    693\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-138>\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/moviepy/decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(f, *a, **kw)\u001b[0m\n\u001b[1;32m     87\u001b[0m         new_kw = {k: fun(v) if k in varnames else v\n\u001b[1;32m     88\u001b[0m                  for (k,v) in kw.items()}\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36mget_frame\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/moviepy/Clip.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;31m#mf = copy(self.make_frame)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mnewclip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_make_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/moviepy/video/VideoClip.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(gf, t)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mby\u001b[0m \u001b[0manother\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mimage_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \"\"\"\n\u001b[0;32m--> 533\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mgf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;31m# --------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-987132afbc30>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0mtransformed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMinv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperspective_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mundistorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0mthresholded_binary_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthresholded_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0mleft_fitx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_fitx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_curvature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mploty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_lane_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthresholded_binary_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject_lane_detection_back_to_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthresholded_binary_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_fitx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_fitx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mploty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMinv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mundistorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mputText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"radius of curvature = {avg_curvature} m\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFONT_HERSHEY_SIMPLEX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-987132afbc30>\u001b[0m in \u001b[0;36mfind_lane_lines\u001b[0;34m(self, binary_warped)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mploty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_warped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary_warped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mleft_fitx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_fitx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mploty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_polynomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleftx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlefty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrightx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrighty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mploty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mavg_curvature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeasure_curvature_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleftx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlefty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrightx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrighty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mploty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-987132afbc30>\u001b[0m in \u001b[0;36mfit_polynomial\u001b[0;34m(self, leftx, lefty, rightx, righty, ploty)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;31m## Check error between current coefficient and on from previous frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mframe_num\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_known_good_left_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft_fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_known_good_right_fit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'frame_num' referenced before assignment"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "frame_num = 0\n",
    "output = 'project_video_output103.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "clip1 = VideoFileClip(\"project_video.mp4\").subclip(37, 45)\n",
    "#clip1 = VideoFileClip(\"challenge_video.mp4\").subclip(0, 7)\n",
    "\n",
    "process_img_obj = ProcessImage(glob.glob('camera_cal/calibration*.jpg'))\n",
    "white_clip = clip1.fl_image(process_img_obj)  #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
